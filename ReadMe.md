# ğŸ’¬ RAG Local avec LM Studio

Ce projet met en place un **RAG (Retrieval-Augmented Generation)** 100% local sous Windows et Macos en utilisant :

- [LM Studio](https://lmstudio.ai) pour la gÃ©nÃ©ration de texte (LLM local, API compatible OpenAI)
- [ChromaDB](https://www.trychroma.com/) pour lâ€™indexation vectorielle
- [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3) comme modÃ¨le dâ€™embeddings multilingue (FR inclus)
- [Streamlit](https://streamlit.io/) pour lâ€™interface web style ChatGPT

ğŸ‘‰ Objectif : poser des questions sur vos propres documents (.pdf, .docx, .txt, .xlsx) et obtenir des rÃ©ponses basÃ©es sur leur contenu.

---

## âš™ï¸ Arborescence

rag_lmstudio/
â”‚â”€â”€ docs/ # Vos documents (peut contenir des sous-dossiers)
â”‚â”€â”€ db/ # Base vectorielle locale (Chroma)
â”‚â”€â”€ .env # Variables d'environnement (API LM Studio, modÃ¨le)
â”‚â”€â”€ requirements.txt # DÃ©pendances Python
â”‚â”€â”€ utils_loaders.py # Fonctions de lecture des fichiers
â”‚â”€â”€ build_index.py # Script dâ€™indexation incrÃ©mentale
â”‚â”€â”€ app.py # Interface web Streamlit (chat)
â”‚â”€â”€ README.md # Documentation du projet

---

## ğŸš€ Installation

### 1. PrÃ©-requis
- **Python 3.10+**
- **NVIDIA GPU** (exploitÃ© via PyTorch CUDA) ou CPU
- [LM Studio](https://lmstudio.ai) installÃ©

### 2. Installer les dÃ©pendances

pip install -r requirements.txt

(choisissez dans le fichier ce qui vous correpond Windows/Macos)


### 3. Configurer LM Studio
- Ouvrir LM Studio
- Aller dans Developer â†’ Local Server et cliquer sur Start
- Charger un modÃ¨le (ex. llama-3.1-8b-instruct)
- VÃ©rifier quâ€™il apparaÃ®t dans la liste des modÃ¨les servis
- âš ï¸ DÃ©cochez Allow local network access pour rester en localhost.



ğŸ”‘ Configuration .env

CrÃ©ez un fichier .env Ã  la racine :

OPENAI_BASE_URL=http://127.0.0.1:1234/v1
OPENAI_API_KEY=lm-studio
LMSTUDIO_MODEL=llama-3.1-8b-instruct   # nom exact du modÃ¨le dans LM Studio


ğŸ“¥ Indexation des documents

Placez vos fichiers dans le dossier docs/ (les sous-dossiers sont pris en charge).

Lancez : python build_index.py


ğŸ’¬ Lancer lâ€™interface

Lancez : streamlit run app.py

Une page web devrait s'ouvrir sinon : http://localhost:8501





FonctionnalitÃ©s :

Interface chat style ChatGPT
Bouton ğŸ” Reconstruire lâ€™index (dans la sidebar)
Affichage des sources et passages utilisÃ©s


## Auteur

Arthur Prigent# RAG-with-LMStudio
